{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports (consolidated in the first cell)\n",
    "import os\n",
    "import pandas as pd\n",
    "import pandas_gbq\n",
    "from google.cloud import bigquery\n",
    "import sqlite3\n",
    "import zipfile\n",
    "\n",
    "# Set up BigQuery client and authentication\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\service_account_key.json'\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Directory where data files are stored\n",
    "data_dir = r'C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data'\n",
    "\n",
    "# Task 1: Data Upload to BigQuery\n",
    "def check_data():\n",
    "    \"\"\"\n",
    "    Queries the BigQuery table to count records by `card_no`\n",
    "    for transactions where `card_no` is not equal to 3.\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT card_no, COUNT(*) as count\n",
    "    FROM `umt-msba.wedge_project_ochoa.transactions`\n",
    "    WHERE card_no != 3\n",
    "    GROUP BY card_no\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "    job = client.query(query)\n",
    "    results = job.result()\n",
    "    for row in results:\n",
    "        print(f\"Card No: {row.card_no}, Count: {row.count}\")\n",
    "\n",
    "def get_owner_records(limit=5):\n",
    "    \"\"\"\n",
    "    Fetches records for owners (excluding card_no == 3) from BigQuery.\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT datetime, register_no, emp_no, trans_no, upc, description, trans_type, card_no\n",
    "    FROM `umt-msba.wedge_project_ochoa.transactions`\n",
    "    WHERE card_no != 3\n",
    "    LIMIT @limit\n",
    "    \"\"\"\n",
    "    job_config = bigquery.QueryJobConfig(\n",
    "        query_parameters=[bigquery.ScalarQueryParameter(\"limit\", \"INT64\", limit)]\n",
    "    )\n",
    "    job = client.query(query, job_config=job_config)\n",
    "    rows = [dict(row) for row in job.result()]\n",
    "    return pd.DataFrame(rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>register_no</th>\n",
       "      <th>emp_no</th>\n",
       "      <th>trans_no</th>\n",
       "      <th>upc</th>\n",
       "      <th>description</th>\n",
       "      <th>trans_type</th>\n",
       "      <th>trans_subtype</th>\n",
       "      <th>trans_status</th>\n",
       "      <th>department</th>\n",
       "      <th>...</th>\n",
       "      <th>batchHeaderID</th>\n",
       "      <th>local</th>\n",
       "      <th>organic</th>\n",
       "      <th>display</th>\n",
       "      <th>receipt</th>\n",
       "      <th>card_no</th>\n",
       "      <th>store</th>\n",
       "      <th>branch</th>\n",
       "      <th>match_id</th>\n",
       "      <th>trans_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-01 07:13:09</td>\n",
       "      <td>51</td>\n",
       "      <td>94</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Change</td>\n",
       "      <td>T</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20074</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-01 08:28:43</td>\n",
       "      <td>51</td>\n",
       "      <td>94</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>T</td>\n",
       "      <td>CC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-09-01 08:44:56</td>\n",
       "      <td>51</td>\n",
       "      <td>94</td>\n",
       "      <td>47</td>\n",
       "      <td>TAX</td>\n",
       "      <td>Tax</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10499</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-09-01 07:20:34</td>\n",
       "      <td>51</td>\n",
       "      <td>94</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Change</td>\n",
       "      <td>T</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12539</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-09-01 08:57:38</td>\n",
       "      <td>51</td>\n",
       "      <td>94</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>T</td>\n",
       "      <td>CC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16360</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  register_no  emp_no  trans_no  upc  description  \\\n",
       "0  2016-09-01 07:13:09           51      94         6    0       Change   \n",
       "1  2016-09-01 08:28:43           51      94        37    0  Credit Card   \n",
       "2  2016-09-01 08:44:56           51      94        47  TAX          Tax   \n",
       "3  2016-09-01 07:20:34           51      94        10    0       Change   \n",
       "4  2016-09-01 08:57:38           51      94        50    0  Credit Card   \n",
       "\n",
       "  trans_type trans_subtype trans_status  department  ...  batchHeaderID  \\\n",
       "0          T            CA          NaN           0  ...            NaN   \n",
       "1          T            CC          NaN           0  ...            NaN   \n",
       "2          A           NaN          NaN           0  ...            NaN   \n",
       "3          T            CA          NaN           0  ...            NaN   \n",
       "4          T            CC          NaN           0  ...            NaN   \n",
       "\n",
       "   local  organic  display  receipt  card_no  store  branch  match_id  \\\n",
       "0    0.0      NaN      NaN      0.0    20074      1       3       0.0   \n",
       "1    0.0      NaN      NaN      0.0        3      1       3       0.0   \n",
       "2    0.0      NaN      NaN      0.0    10499      1       3       0.0   \n",
       "3    0.0      NaN      NaN      0.0    12539      1       3       0.0   \n",
       "4    0.0      NaN      NaN      0.0    16360      1       3       0.0   \n",
       "\n",
       "   trans_id  \n",
       "0         7  \n",
       "1         7  \n",
       "2        12  \n",
       "3         9  \n",
       "4        11  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Use raw string for file path\n",
    "file_path = r'C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201609_clean.csv'\n",
    "\n",
    "# Read the CSV file, correcting escape character issues\n",
    "df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N', r'\\\\N'])\n",
    "\n",
    "# Display the first few rows of the dataframe to inspect it\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201001_201003_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:03, 183.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2998330 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201004_201006_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:02, 183.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 3185807 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201007_201009_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:00, 180.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2992585 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201010_201012_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\347415063.py:30: DtypeWarning: Columns (43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [03:22, 202.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2957586 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201101_201103_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [04:49, 289.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2920826 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201104_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:23, 83.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 1066334 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201105_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:28, 88.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 1068515 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201106_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:11, 71.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 992906 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201107_201109_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:17, 197.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 3011935 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201110_201112_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:41, 221.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 3121117 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201201_201203_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [14:06, 846.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2989644 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201201_201203_inactive_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:20, 20.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 245772 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201204_201206_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\347415063.py:30: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [03:33, 213.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 3083546 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201204_201206_inactive_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:30, 30.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 237990 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201207_201209_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\347415063.py:30: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [03:20, 200.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2925608 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201207_201209_inactive_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\347415063.py:30: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [00:19, 19.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 190877 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201210_201212_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\347415063.py:30: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [03:01, 181.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2893637 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201210_201212_inactive_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\347415063.py:30: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [00:15, 15.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 162988 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201301_201303_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\347415063.py:30: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [03:19, 199.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2903987 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201301_201303_inactive_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\347415063.py:30: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [00:17, 17.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 148623 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201304_201306_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\347415063.py:30: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [07:10, 430.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 3025434 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201304_201306_inactive_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\347415063.py:30: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [00:18, 18.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 137628 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201307_201309_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\347415063.py:30: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [03:24, 204.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2997135 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201307_201309_inactive_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:11, 11.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 104468 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201310_201312_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\347415063.py:30: DtypeWarning: Columns (33,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [03:27, 207.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2922057 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201310_201312_inactive_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:08,  8.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 79156 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201401_201403_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\347415063.py:30: DtypeWarning: Columns (33,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [03:35, 215.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2916194 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201401_201403_inactive_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\347415063.py:30: DtypeWarning: Columns (43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [00:11, 11.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 52614 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201404_201406_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\347415063.py:30: DtypeWarning: Columns (33,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [03:30, 210.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 3154267 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201404_201406_inactive_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:08,  8.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 49069 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201407_201409_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:19, 199.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 3030409 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201407_201409_inactive_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:06,  6.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 28323 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201410_201412_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:24, 204.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2931416 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201410_201412_inactive_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 7964 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201501_201503_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:45, 225.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 3041129 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201504_201506_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:41, 221.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 3274964 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201507_201509_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:19, 199.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 3124699 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201510_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:35, 95.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 1006055 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201511_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:35, 95.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 993744 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201512_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:27, 87.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 960017 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201601_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:20, 80.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 979408 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201602_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:15, 75.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 874853 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201603_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:29, 89.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 964635 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201604_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:18, 78.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 930359 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201605_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:17, 77.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 938769 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201606_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:11, 71.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 862329 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201607_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:17, 77.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 872161 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201608_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:17, 77.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 858168 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201609_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:06, 66.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 861248 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201610_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:07, 67.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 905092 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201611_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:10, 70.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 925314 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201612_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:12, 72.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 915707 rows to wedge_project_ochoa.transactions\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201701_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:12, 72.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 936741 rows to wedge_project_ochoa.transactions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to upload a DataFrame to BigQuery and append to a single table\n",
    "def upload_to_bigquery(df, table_name=\"transactions\"):\n",
    "    table_id = f\"wedge_project_ochoa.{table_name}\" \n",
    "   \n",
    "    \n",
    "    # Upload the DataFrame to BigQuery using pandas_gbq and append to the table\n",
    "    pandas_gbq.to_gbq(\n",
    "        df, \n",
    "        table_id, \n",
    "        project_id=\"umt-msba\", \n",
    "        if_exists=\"append\", \n",
    "        api_method=\"load_csv\"\n",
    "    )\n",
    "\n",
    "    print(f\"Uploaded {len(df)} rows to {table_id}\")\n",
    "\n",
    "# Loop through all CSV files in the directory and upload each to BigQuery\n",
    "for file_name in os.listdir(data_dir):\n",
    "    if file_name.endswith('.csv'): \n",
    "        file_path = os.path.join(data_dir, file_name)\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        \n",
    "        # Read the CSV into a DataFrame\n",
    "        df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
    "        \n",
    "        # Upload the DataFrame to the 'transactions' table in BigQuery\n",
    "        upload_to_bigquery(df, table_name=\"transactions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 2 \n",
    "\n",
    "# Set up BigQuery authentication\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\service_account_key.json'\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Check for the number of records with card_no not equal to 3\n",
    "def check_data():\n",
    "    query = \"\"\"\n",
    "    SELECT card_no, COUNT(*) as count\n",
    "    FROM `umt-msba.wedge_project_ochoa.transactions`\n",
    "    WHERE card_no != 3\n",
    "    GROUP BY card_no\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "    job = client.query(query)\n",
    "    \n",
    "    # Get results\n",
    "    results = job.result()\n",
    "    \n",
    "    # Print results to confirm that data exists\n",
    "    for row in results:\n",
    "        print(f\"Card No: {row.card_no}, Count: {row.count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for owner records (excluding card_no == 3)\n",
    "def get_owner_records(limit=5):\n",
    "    query = \"\"\"\n",
    "    SELECT datetime, register_no, emp_no, trans_no, upc, description, trans_type, card_no\n",
    "    FROM `umt-msba.wedge_project_ochoa.transactions`\n",
    "    WHERE card_no != 3\n",
    "    LIMIT @limit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Configuring query parameters\n",
    "    job_config = bigquery.QueryJobConfig(\n",
    "        query_parameters=[\n",
    "            bigquery.ScalarQueryParameter(\"limit\", \"INT64\", limit)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Running the query\n",
    "    job = client.query(query, job_config=job_config)\n",
    "    \n",
    "    # Fetch the results directly without schema checks for now\n",
    "    results = job.result()\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    rows = [dict(row) for row in results]\n",
    "    if not rows:\n",
    "        raise ValueError(\"No rows fetched, check if your query conditions are correct.\")\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    print(\"First few rows of the DataFrame:\", df.head())\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current file size: 96.98 MB, increasing sample size to 300\n",
      "Current file size: 117.68 MB, increasing sample size to 350\n",
      "Current file size: 133.91 MB, increasing sample size to 400\n",
      "Current file size: 162.88 MB, increasing sample size to 450\n",
      "Current file size: 183.22 MB, increasing sample size to 500\n",
      "Current file size: 208.98 MB, increasing sample size to 550\n",
      "Current file size: 223.95 MB, increasing sample size to 600\n",
      "Current file size: 247.58 MB, increasing sample size to 650\n",
      "Achieved target size with sample size 650: 263.69 MB\n",
      "Successfully wrote 1454891 records for sampled owners to 'sampled_owners_250MB.txt'.\n"
     ]
    }
   ],
   "source": [
    "# Task 2:\n",
    "\n",
    "# Set up BigQuery authentication\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\service_account_key.json'\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Step 1: Fetch a list of all owners excluding card_no == 3\n",
    "def get_owners_list():\n",
    "    query = \"\"\"\n",
    "    SELECT DISTINCT card_no\n",
    "    FROM `umt-msba.wedge_project_ochoa.transactions`\n",
    "    WHERE card_no != 3\n",
    "    \"\"\"\n",
    "    results = client.query(query).result()\n",
    "    \n",
    "    # Convert the results to a DataFrame to work with the list of owners\n",
    "    owners_df = pd.DataFrame([row.card_no for row in results], columns=['card_no'])\n",
    "    return owners_df\n",
    "\n",
    "# Step 2: Sample a subset of owners based on a sample size\n",
    "def sample_owners(owners_df, sample_size):\n",
    "    sampled_owners = owners_df.sample(n=sample_size, random_state=42)\n",
    "    return sampled_owners\n",
    "\n",
    "# Step 3: Extract all records associated with the sampled owners\n",
    "def extract_records_for_sampled_owners(sampled_owners):\n",
    "    # Convert the list of sampled owner IDs to a string for the SQL IN clause\n",
    "    owner_ids = tuple(sampled_owners['card_no'].tolist())\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM `umt-msba.wedge_project_ochoa.transactions`\n",
    "    WHERE card_no IN {owner_ids}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the query and store the results in a DataFrame\n",
    "    results = client.query(query).result()\n",
    "    records_df = pd.DataFrame([dict(row) for row in results])\n",
    "    return records_df\n",
    "\n",
    "# Step 4: Write the sampled records to a local text file\n",
    "def write_sample_to_file(df, output_file):\n",
    "    df.to_csv(output_file, sep='\\t', index=False)\n",
    "\n",
    "# Step 5: Dynamically adjust sample size to achieve 250 MB file size\n",
    "def get_250mb_sample(owners_df, initial_sample_size=250, target_size_mb=250):\n",
    "    sample_size = initial_sample_size\n",
    "    file_path = \"test_sample.txt\"\n",
    "    \n",
    "    while True:\n",
    "        # Sample owners and extract their records\n",
    "        sampled_owners = sample_owners(owners_df, sample_size=sample_size)\n",
    "        sampled_records = extract_records_for_sampled_owners(sampled_owners)\n",
    "        \n",
    "        # Write a test sample to file\n",
    "        sampled_records.to_csv(file_path, sep='\\t', index=False)\n",
    "        file_size = os.path.getsize(file_path) / (1024 * 1024)  # Size in MB\n",
    "        \n",
    "        if file_size >= target_size_mb:\n",
    "            print(f\"Achieved target size with sample size {sample_size}: {file_size:.2f} MB\")\n",
    "            return sampled_records  # Return the DataFrame when target size is met\n",
    "        \n",
    "        # Increase the sample size if file is too small\n",
    "        sample_size += 50\n",
    "        print(f\"Current file size: {file_size:.2f} MB, increasing sample size to {sample_size}\")\n",
    "\n",
    "# Workflow Function (No `if __name__ == \"__main__\"`)\n",
    "def generate_250mb_sample(output_file='sampled_owners_250MB.txt'):\n",
    "    # Step 1: Get all distinct owner IDs excluding card_no == 3\n",
    "    owners = get_owners_list()\n",
    "    \n",
    "    # Step 2: Dynamically adjust sample size to achieve 250 MB\n",
    "    sampled_records = get_250mb_sample(owners, initial_sample_size=250, target_size_mb=250)\n",
    "    \n",
    "    # Step 3: Write the final sample to a local text file\n",
    "    write_sample_to_file(sampled_records, output_file=output_file)\n",
    "\n",
    "    print(f\"Successfully wrote {len(sampled_records)} records for sampled owners to '{output_file}'.\")\n",
    "\n",
    "# Call the main workflow directly\n",
    "generate_250mb_sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jochoa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\cloud\\bigquery\\table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jochoa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\cloud\\bigquery\\table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jochoa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\cloud\\bigquery\\table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQLite database 'wedge_summary.db' created with all summary tables.\n"
     ]
    }
   ],
   "source": [
    "## Task 3\n",
    "\n",
    "# Set up BigQuery authentication\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\service_account_key.json'\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Helper function to run a query and return a DataFrame\n",
    "def query_to_dataframe(query):\n",
    "    job = client.query(query)\n",
    "    return job.result().to_dataframe()\n",
    "\n",
    "# Summary table 1: Sales by date by hour\n",
    "def create_sales_by_date_by_hour():\n",
    "    query = \"\"\"\n",
    "    SELECT\n",
    "        DATETIME_TRUNC(DATETIME(datetime), HOUR) AS datetime_hour,\n",
    "        EXTRACT(DATE FROM DATETIME(datetime)) AS date,\n",
    "        EXTRACT(HOUR FROM DATETIME(datetime)) AS hour,\n",
    "        SUM(total) AS total_sales,  -- Using 'total' column as the total sales amount\n",
    "        COUNT(trans_no) AS transactions,\n",
    "        SUM(CASE WHEN trans_status = '' OR trans_status = ' ' THEN quantity ELSE 0 END) AS items\n",
    "    FROM `umt-msba.wedge_project_ochoa.transactions`\n",
    "    WHERE trans_status NOT IN ('R', 'V')\n",
    "    GROUP BY datetime_hour, date, hour\n",
    "    ORDER BY date, hour\n",
    "    \"\"\"\n",
    "    return query_to_dataframe(query)\n",
    "\n",
    "# Summary table 2: Sales by owner by year by month\n",
    "def create_sales_by_owner_by_year_by_month():\n",
    "    query = \"\"\"\n",
    "SELECT card_no,\n",
    "                   EXTRACT(YEAR from datetime) as year,\n",
    "                   EXTRACT(MONTH from datetime) as month,\n",
    "                   ROUND(SUM(total),2) AS sales,\n",
    "                   COUNT(distinct(\n",
    "                      CONCAT(CAST(EXTRACT(DATE from datetime) AS STRING),\n",
    "                             CAST(register_no AS STRING),\n",
    "                             CAST(emp_no AS STRING),\n",
    "                             CAST(trans_no AS STRING)))) as transactions,\n",
    "                   SUM(CASE WHEN (trans_status = 'V' or trans_status = 'R') THEN -1 ELSE 1 END) as items\n",
    "                   FROM `umt-msba.wedge_transactions.transArchive_*`\n",
    "                     WHERE department != 0 and\n",
    "                          department != 15 and\n",
    "                         (trans_status IS NULL or \n",
    "                          trans_status = ' ' or \n",
    "                          trans_status = 'V' or \n",
    "                          trans_status = 'R') \n",
    "                    GROUP BY card_no, year, month\n",
    "                    ORDER BY card_no, year, month    \n",
    "    \"\"\"\n",
    "    return query_to_dataframe(query)\n",
    "\n",
    "# Summary table 3: Sales by product description by year by month\n",
    "def create_sales_by_product_by_year_by_month():\n",
    "    query = \"\"\"\n",
    "    SELECT\n",
    "        upc,\n",
    "        description,\n",
    "        department AS department_number,\n",
    "        EXTRACT(YEAR FROM DATETIME(datetime)) AS year,\n",
    "        EXTRACT(MONTH FROM DATETIME(datetime)) AS month,\n",
    "        SUM(total) AS total_sales,  -- Using 'total' column as the total sales amount\n",
    "        COUNT(trans_no) AS transactions,\n",
    "        SUM(quantity) AS items\n",
    "    FROM `umt-msba.wedge_project_ochoa.transactions`\n",
    "    GROUP BY upc, description, department_number, year, month\n",
    "    ORDER BY upc, year, month\n",
    "    \"\"\"\n",
    "    return query_to_dataframe(query)\n",
    "\n",
    "# Function to create SQLite database and populate it with summary tables\n",
    "def build_sqlite_database(db_file='wedge_summary.db'):\n",
    "    # Create a SQLite connection\n",
    "    conn = sqlite3.connect(db_file)\n",
    "    \n",
    "    # Create 'sales_by_date_by_hour' table\n",
    "    sales_by_date = create_sales_by_date_by_hour()\n",
    "    sales_by_date.to_sql('sales_by_date_by_hour', conn, if_exists='replace', index=False)\n",
    "    \n",
    "    # Create 'sales_by_owner_by_year_by_month' table\n",
    "    sales_by_owner = create_sales_by_owner_by_year_by_month()\n",
    "    sales_by_owner.to_sql('sales_by_owner_by_year_by_month', conn, if_exists='replace', index=False)\n",
    "    \n",
    "    # Create 'sales_by_product_description_by_year_by_month' table\n",
    "    sales_by_product = create_sales_by_product_by_year_by_month()\n",
    "    sales_by_product.to_sql('sales_by_product_description_by_year_by_month', conn, if_exists='replace', index=False)\n",
    "    \n",
    "    # Commit changes and close the connection\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(\"SQLite database 'wedge_summary.db' created with all summary tables.\")\n",
    "\n",
    "# Run the main workflow\n",
    "if __name__ == \"__main__\":\n",
    "    build_sqlite_database()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created wedge_summary.zip\n"
     ]
    }
   ],
   "source": [
    "## Zip the File\n",
    "\n",
    "import zipfile\n",
    "\n",
    "# Define the path to your .db file\n",
    "db_file = 'wedge_summary.db'\n",
    "zip_file = 'wedge_summary.zip'\n",
    "\n",
    "# Create a zip file\n",
    "with zipfile.ZipFile(zip_file, 'w') as zipf:\n",
    "    zipf.write(db_file)\n",
    "\n",
    "print(f\"Successfully created {zip_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully split the zip file into smaller parts.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Define the path to the original .db file and the new .zip file\n",
    "db_file = 'wedge_summary.db'\n",
    "zip_file = 'wedge_summary.zip'\n",
    "\n",
    "# Compress the .db file into a .zip archive\n",
    "with zipfile.ZipFile(zip_file, 'w') as zipf:\n",
    "    zipf.write(db_file)\n",
    "\n",
    "# Split the .zip file into smaller parts of 45 MB each\n",
    "def split_file(file_path, part_size=45 * 1024 * 1024):  # 45 MB parts\n",
    "    part_number = 1\n",
    "    with open(file_path, 'rb') as f:\n",
    "        while True:\n",
    "            chunk = f.read(part_size)\n",
    "            if not chunk:\n",
    "                break\n",
    "            part_file = f\"{file_path}.part{str(part_number).zfill(2)}\"\n",
    "            with open(part_file, 'wb') as pf:\n",
    "                pf.write(chunk)\n",
    "            part_number += 1\n",
    "\n",
    "# Call the split function\n",
    "split_file(zip_file)\n",
    "print(\"Successfully split the zip file into smaller parts.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
